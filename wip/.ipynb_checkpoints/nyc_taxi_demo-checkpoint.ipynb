{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyMapD and PyGDF Demo on NY Taxi Data Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use PyMapD to create and populate a table of NY Taxi data from a CSV file.  Then, we query the MapD database to get a PyGDF GPU dataframe and manipulate the data using groupby, join and other dataframe operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cuml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompress CSV archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -kf /rapids/notebooks/wip/notebooks-extended/data/nytaxi/nytaxi_pre_mapd_200k.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to MapD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vendor_id', 'rate_code', 'store_and_fwd_flag', 'passenger_count', 'trip_time_in_secs', 'trip_distance', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'tolls_amount', 'tip_amount', 'total_amount', 'mta_tax', 'fare_amount', 'payment_type', 'surcharge', 'pickup_datetime_year', 'pickup_datetime_month', 'pickup_datetime_day', 'pickup_datetime_hours', 'dropoff_datetime_year', 'dropoff_datetime_month', 'dropoff_datetime_day', 'dropoff_datetime_hours']\n",
      "['object', 'int', 'object', 'int', 'int', 'float64', 'float64', 'float64', 'date', 'date', 'float64', 'float64', 'float64', 'float64', 'float64', 'object', 'float64', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"df2 = cudf.io.csv.read_csv_strings('/rapids/notebooks/wip/notebooks-extended/data/nytaxi/nytaxi_pre_mapd_200k.csv', delimiter=',',\\n                                       names = dnames,\\n                                       dtype= types,\\n                                       quoting=True,\\n                                       doublequote=False,\\n                                       skiprows=1)\\nprint(df2)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cudf.read_csv(\"/rapids/notebooks/wip/notebooks-extended/data/nytaxi/nytaxi_pre_mapd_200k.csv\")\n",
    "#print(df.dtypes)\n",
    "dnames = list(df)\n",
    "types = []\n",
    "for i in range (len(list(df))):\n",
    "    tdtype = str(df.dtypes[i])\n",
    "    if(tdtype == 'int32'):\n",
    "        tdtype = 'str'\n",
    "    elif(tdtype == 'int64'):\n",
    "        tdtype = 'int'\n",
    "    elif(tdtype == 'datetime64[ms]'):\n",
    "        tdtype = 'date'\n",
    "    types.append(tdtype)\n",
    "\n",
    "print(dnames)\n",
    "print(types)\n",
    "'''df2 = cudf.io.csv.read_csv_strings('/rapids/notebooks/wip/notebooks-extended/data/nytaxi/nytaxi_pre_mapd_200k.csv', delimiter=',',\n",
    "                                       names = dnames,\n",
    "                                       dtype= types,\n",
    "                                       quoting=True,\n",
    "                                       doublequote=False,\n",
    "                                       skiprows=1)\n",
    "print(df2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   vendor_id  rate_code  store_and_fwd_flag  passenger_count  trip_time_in_secs       trip_distance    pickup_longitude ...  dropoff_datetime_hours\n",
      "0        CMT          1                   N                4                382                 1.0          -73.978165 ...                      15\n",
      "1        CMT          1                   N                1                259                 1.5  -74.00668300000001 ...                       0\n",
      "2        CMT          1                   N                1                282                 1.1          -74.004707 ...                      18\n",
      "3        CMT          1                   N                2                244  0.7000000000000001          -73.974602 ...                      23\n",
      "4        CMT          1                   N                1                560                 2.1  -73.97625000000001 ...                      23\n",
      "[17 more columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vendor_id                         object\n",
       "rate_code                          int64\n",
       "store_and_fwd_flag                object\n",
       "passenger_count                    int64\n",
       "trip_time_in_secs                  int64\n",
       "trip_distance                    float64\n",
       "pickup_longitude                 float64\n",
       "pickup_latitude                  float64\n",
       "dropoff_longitude         datetime64[ms]\n",
       "dropoff_latitude          datetime64[ms]\n",
       "tolls_amount                     float64\n",
       "tip_amount                       float64\n",
       "total_amount                     float64\n",
       "mta_tax                          float64\n",
       "fare_amount                      float64\n",
       "payment_type                      object\n",
       "surcharge                        float64\n",
       "pickup_datetime_year               int64\n",
       "pickup_datetime_month              int64\n",
       "pickup_datetime_day                int64\n",
       "pickup_datetime_hours              int64\n",
       "dropoff_datetime_year              int64\n",
       "dropoff_datetime_month             int64\n",
       "dropoff_datetime_day               int64\n",
       "dropoff_datetime_hours             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   vendor_id  rate_code  store_and_fwd_flag  passenger_count  trip_time_in_secs       trip_distance    pickup_longitude ...  dropoff_datetime_hours\n",
      "0        CMT          1                   N                4                382                 1.0          -73.978165 ...                      15\n",
      "1        CMT          1                   N                1                259                 1.5  -74.00668300000001 ...                       0\n",
      "2        CMT          1                   N                1                282                 1.1          -74.004707 ...                      18\n",
      "3        CMT          1                   N                2                244  0.7000000000000001          -73.974602 ...                      23\n",
      "4        CMT          1                   N                1                560                 2.1  -73.97625000000001 ...                      23\n",
      "[17 more columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    CSH\n",
      "1    CSH\n",
      "2    CSH\n",
      "3    CSH\n",
      "4    CSH\n",
      "5    CSH\n",
      "6    CSH\n",
      "7    CSH\n",
      "8    CSH\n",
      "9    CSH\n",
      "[199990 more rows]\n",
      "Name: payment_type, dtype: object 0    CMT\n",
      "1    CMT\n",
      "2    CMT\n",
      "3    CMT\n",
      "4    CMT\n",
      "5    CMT\n",
      "6    CMT\n",
      "7    CMT\n",
      "8    CMT\n",
      "9    CMT\n",
      "[199990 more rows]\n",
      "Name: vendor_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"payment_type\"], df[\"vendor_id\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-29b9197729b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'foo3.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.7/site-packages/cudf-0.6.1+1.g9ca9325-py3.7-linux-x86_64.egg/cudf/dataframe/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'DataFrame' object has no attribute %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "df.to_csv('foo3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows 200000\n"
     ]
    }
   ],
   "source": [
    "print('nrows', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby lat lon grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to group each record by their pickup location. We will to round the lat lon with the ``round_latlon`` method.  By using ``.applymap``, the rounding method will be compiled into GPU code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "def round_latlon(x):\n",
    "    scale = 5\n",
    "    return floor(x * scale) / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.0\n",
      "6    0.0\n",
      "7    0.0\n",
      "8    0.0\n",
      "9    0.0\n",
      "[199990 more rows]\n",
      "Name: tip_amount, dtype: float64\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.0\n",
      "6    0.0\n",
      "7    0.0\n",
      "8    0.0\n",
      "9    0.0\n",
      "[199990 more rows]\n",
      "Name: tip_ratio, dtype: float64 0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.0\n",
      "6    0.0\n",
      "7    0.0\n",
      "8    0.0\n",
      "9    0.0\n",
      "[199990 more rows]\n",
      "Name: tip_amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "group_df = df.loc[:, ['pickup_longitude', 'pickup_latitude', 'tip_amount', 'fare_amount']] \n",
    "print(df['tip_amount'])\n",
    "group_df['pickup_longitude'] = group_df['pickup_longitude'].applymap(round_latlon)\n",
    "group_df['pickup_latitude'] = group_df['pickup_latitude'].applymap(round_latlon)\n",
    "\n",
    "group_df['tip_ratio'] = group_df['tip_amount'] / group_df['fare_amount']\n",
    "print(group_df['tip_ratio'], group_df['tip_amount'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_longitude    float64\n",
       "pickup_latitude     float64\n",
       "tip_amount          float64\n",
       "fare_amount         float64\n",
       "tip_ratio           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group df rows 200000\n",
      "   pickup_longitude  pickup_latitude  tip_amount  fare_amount  tip_ratio\n",
      "0             -74.0             40.6         0.0          6.5        0.0\n",
      "1             -74.2             40.6         0.0          6.0        0.0\n",
      "2             -74.2             40.6         0.0          5.5        0.0\n",
      "3             -74.0             40.6         0.0          5.0        0.0\n",
      "4             -74.0             40.6         0.0          9.5        0.0\n"
     ]
    }
   ],
   "source": [
    "print('group df rows', len(group_df))\n",
    "print(group_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we run groupby and specify the aggregating methods on each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Groupby' object has no attribute 'std'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1b709f4226bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgrouped_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pickup_longitude'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pickup_latitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgrouped_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pickup_longitude'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pickup_latitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fare_amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#grouped_std = grouped_stats.std()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.7/site-packages/cudf-0.6.1+1.g9ca9325-py3.7-linux-x86_64.egg/cudf/groupby/groupby.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_val_columns'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_val_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'Groupby' object has no attribute %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Groupby' object has no attribute 'std'"
     ]
    }
   ],
   "source": [
    "from numba import cuda,jit,float32\n",
    "\n",
    "# Aggregating methods to apply to each column\n",
    "\n",
    "aggs = {\n",
    "    'tip_amount': ['mean'],\n",
    "    'fare_amount': ['mean', 'count'], ##std is not currently impletmented in RAPIDS 0.5.1.  Therefore, we need a work around (thanks Jiwei Liu!)\n",
    "    'tip_ratio': ['mean']\n",
    "}\n",
    "\n",
    "grouped_stats = group_df.groupby(['pickup_longitude', 'pickup_latitude']).agg(aggs)\n",
    "grouped_std = group_df.groupby(['pickup_longitude', 'pickup_latitude'])['fare_amount'].std()\n",
    "#grouped_std = grouped_stats.std()\n",
    "\n",
    "grouped_std = [group_df['fare_amount'].std()]*len(grouped_stats) ### STD is a SPSA method, while the other aggs are SPMA.  This requires us to calculate it seperatedly, put the values in an series  of ismilar size, and then join it to the dataframe\n",
    "grouped_stats['std_fare_amount'] = grouped_std\n",
    "print('total groups', len(grouped_stats))\n",
    "print(grouped_stats.head())\n",
    "print(grouped_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder the grouped dataframe by `count_fare_amount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grouped_stats.sort_values('count_fare_amount', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby payment type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also group by categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_pay = df.loc[:, ['payment_type', 'tip_amount', 'fare_amount']]\n",
    "print(group_pay)\n",
    "group_pay['tip_ratio'] = group_df['tip_ratio']\n",
    "print(group_df['tip_ratio'])\n",
    "groupby_payment = group_pay.groupby(['payment_type']).mean()\n",
    "display(groupby_payment.sort_values('mean_tip_ratio', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompress CSV archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -kf ./data/nytaxi/nytaxi_pre_mapd_200k.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest data from MapD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = con.select_ipc_gpu(\"\"\"\n",
    "SELECT  \n",
    "payment_type, pickup_longitude, pickup_latitude, tip_amount, total_amount, fare_amount\n",
    "FROM nytaxi_subset \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the type of the result from `con.select_ipc_gpu` is a GPU dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('nrows', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "def round_latlon(x):\n",
    "    scale = 5\n",
    "    return floor(x * scale) / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_df = df.loc[:, ['pickup_longitude', 'pickup_latitude', 'tip_amount', 'fare_amount']] \n",
    "\n",
    "group_df['pickup_longitude'] = group_df['pickup_longitude'].applymap(round_latlon)\n",
    "group_df['pickup_latitude'] = group_df['pickup_latitude'].applymap(round_latlon)\n",
    "\n",
    "group_df['tip_ratio'] = group_df['tip_amount'] / group_df['fare_amount']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we run groupby and specify the aggregating methods on each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Aggregating methods to apply to each column\n",
    "grouped_std = group_df['fare_amount'].std()\n",
    "aggs = {\n",
    "    'tip_amount': ['mean'],\n",
    "    'fare_amount': ['mean', 'count'], ##std is not currently impletmented in RAPIDS 0.5.1.  Therefore, we need a work around (thanks Jiwei Liu!)\n",
    "    'tip_ratio': ['mean']\n",
    "}\n",
    "print(aggs)\n",
    "print(len(aggs))\n",
    "\n",
    "#print(group_df.groupby(['pickup_longitude', 'pickup_latitude']).agg(aggs))\n",
    "grouped_stats = group_df.groupby(['pickup_longitude', 'pickup_latitude']).agg(aggs)\n",
    "#grouped_stats = group_stats.assign(std_fare_amount=grouped_std)\n",
    "for i in range(len(grouped_stats)):\n",
    "    grouped_stats[i].std_fare_amount= grouped_std\n",
    "\n",
    "print('total groups', len(grouped_stats))\n",
    "grouped_stats.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder the grouped dataframe by `fare_amount_count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_stats.sort_values('fare_amount_count', ascending=False).head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby payment type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also group by categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_pay = df.loc[:, ['payment_type', 'tip_amount', 'fare_amount']]\n",
    "group_pay['tip_ratio'] = group_df['tip_ratio']\n",
    "\n",
    "groupby_payment = group_pay.groupby(['payment_type']).mean()\n",
    "groupby_payment.sort_values('tip_ratio', ascending=False).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join table with payment_type meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `.join()` to add a description column for each payment type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "payment_code = {\n",
    "    'CRD': 'Credit Card',\n",
    "    'CSH': 'Cash',\n",
    "    'NOC': 'No Charge',\n",
    "    'DIS': 'Dispute',\n",
    "    'UNK': 'Unknown',\n",
    "}\n",
    "\n",
    "payment_meaning = pygdf.DataFrame()\n",
    "\n",
    "# Customize codes.dtype to match storage type from mapd\n",
    "src_cat = group_pay.payment_type\n",
    "cat = pandas.Categorical(payment_code.keys(), categories=src_cat.cat.categories)\n",
    "payment_meaning['payment_type'] = pygdf.Series.from_categorical(cat, codes=cat.codes.astype(src_cat.data.dtype))\n",
    "\n",
    "payment_meaning['payment_meaning'] = pandas.Categorical(payment_code.values())\n",
    "payment_meaning = payment_meaning.set_index('payment_type')\n",
    "\n",
    "payment_meaning.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = groupby_payment.set_index('payment_type').join(payment_meaning)\n",
    "joined.sort_values('tip_ratio', ascending=False).to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
